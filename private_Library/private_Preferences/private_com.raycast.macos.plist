bplist00ßS	
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUTTTTZ[T]^T`abTT„…TŸT¡¢£T¥¦²¶T¸TºT¼½T¿£TTÃ£ÅÈTÊËTÍÎÏĞÑTÓ£TT×TÙTÛÜTT£TáæçèTê£ìT£ï_store_migratedReminders_raycastAnonymousId_-permissions.folders.read:/Users/flo/Downloads_%permissions.folders.read:cloudStorage_Scommand-extension_raynab.unreviewed__319782b6-6050-4568-89b5-194c84709f83_activated_)fallbackSearches_didMigrateScriptCommands_!NSNavPanelExpandedSizeForOpenMode_cloudSync_lastSyncDate_#raycastShouldFollowSystemAppearance_raycastAI_ollamaModelsList_"raycast-preferences-restorableData_'didMigrationForClipboardHistoryFavicons_NSWindow Frame ai-chat-window_raycastAI_lastSelectedChatId_mainWindowPositionCache_raycastAI_modelInfo_-permissions.folders.read:/Users/flo/Documents_)permissions.folders.read:removableVolumes_`command-extension_raynab.transaction__319782b6-6050-4568-89b5-194c84709f83-cleared_previousValue_store_everInstalled_raycastAiHasSeenQuickAI_$floatingNotes_lastSelectedDocumentId_raycastGlobalHotkey_,floatingNotes_didMigrateFloatingNotesRecords_cNSStatusItem Preferred Position extension_toggl-track_menuBar__ce226a1f-7f1c-4680-8735-aa462793bca5_+NSStatusItem Preferred Position raycastIcon_hasQueuedStatusBarHint_store_termsAccepted_%NSWindow Frame NSNavPanelAutosaveName_#onboarding_completedTaskIdentifiers_"commandsPreferencesExpandedItemIds_'raycast-updates-whatsNewItemDisplayDate_store_migratedNative_+floatingNotes_raycastNotesNavigateBackStack_onboarding_setupAlias_raycastPreferredWindowMode_%floatingNotes_didCreateOnboardingNote_commandScheduler_commandRuns_,raycast-updates-lastTargetCommitishInstalled_<raycastAccountService_proPlanWalkthroughShownOnCurrentDevice_calculator_currenciesRefresh_NSStatusItem Visible Item-1_$mainWindow_isMonitoringGlobalHotkeys_store_migratedHackerNews_.floatingNotes_raycastNotesNavigateForwardStack_*floatingNotes_raycastNotesFormatBarVisible_)NSSplitView Subview Frames raycast_aiChat_$raycastCurrentThemeIdLightAppearance_$hasShownStatusBarHintAfterOnboarding_(commandsPreferencesLastSelectedFilterTab_database_lastValidAppVersion_6floatingNotes_didMigrateFloatingNotesHotkeysAndAliases_&raycast-updates-lastAppUpdateCheckDate_"aiDynamicPlaceholdersMigrationDate_raycastFirstKnownAppVersion_raycastInstallationDate_#raycastCurrentThemeIdDarkAppearance_Ucommand-extension_toggl-track.menuBar__ce226a1f-7f1c-4680-8735-aa462793bca5_activated_,typingPractice_typingPracticeSelectedModeKey_showGettingStartedLink_onboardingCompleted_onboarding_setupHotkey_raycastUI_preferredTextSize_+permissions.folders.read:/Users/flo/Desktop_raycastLoginItemAutoInstalled_XNSStatusItem Visible extension_toggl-track_menuBar__ce226a1f-7f1c-4680-8735-aa462793bca5_0amplitudePulseAnalyticsTracker_nextHeartbeatDate_kextension_paste-as-plain-text.paste-as-plain-text__30f5a222-3c9a-4edd-834d-649943634272_advancedPasteFormat_/raycastAccountService_cloudSyncWalkthroughShown_subscriptions_active_$subscriptions_needsProTrialEnrolment_VNSStatusItem Visible extension_raynab_unreviewed__319782b6-6050-4568-89b5-194c84709f83_onboarding_raycastShortcuts_faviconProvider_NSOSPLastRootDirectory_aNSStatusItem Preferred Position extension_raynab_unreviewed__319782b6-6050-4568-89b5-194c84709f83_!cloudSync_ensurePresetSyncRecords_database_lastValidOSVersion_useHyperKeyIcon_raycastAI_remoteExtensions_onboarding_showTasksProgress_NSStatusItem Visible Item-2_#NSWindow Frame raycast-notes-window	_$129972E2-670A-44A2-B929-2EA2076FFFDC				Z{800, 448}3AÆàvª?	B[]OL{"typeName":"ExtensionsPreferencesTabItem","persistenceDate":764883361.2385}	_600 101 647 1000 0 0 1800 1125 _$48335B69-1425-443B-BDC9-B11551EB764Eßcdefghijklmnopqrstuvwxyz{|}~€_2(84.0, 982.0, 5120.0, 1440.0)_ 3(433.0, 1169.0, 5120.0, 1440.0)_2(84.0, 1169.0, 5120.0, 1440.0)_1(0.0, 0.0, 1800.0, 1125.0)_28(0.0, 0.0, 1920.0, 1080.0)_1(0.0, 0.0, 1352.0, 878.0)_51(0.0, 0.0, 1920.0, 1080.0)_4(0.0, 0.0, 1920.0, 1080.0)_ 2(433.0, 1169.0, 5120.0, 1440.0)_1(0.0, 0.0, 1920.0, 1200.0)_3(84.0, 1169.0, 5120.0, 1440.0)_1(0.0, 0.0, 1512.0, 982.0)_3(84.0, 878.0, 5120.0, 1440.0)_1(0.0, 0.0, 1800.0, 1169.0)_3(84.0, 982.0, 5120.0, 1440.0)\{2269, 2161}\{2606, 2348}\{2257, 2348}Z{525, 949}Z{573, 916}Z{289, 769}Z{573, 916}Z{573, 916}\{2606, 2348}[{585, 1004}\{2257, 2348}Z{525, 938}\{2257, 2057}Z{513, 981}\{2257, 2161}OtÜ{"models":[{"requires_better_ai":false,"abilities":{"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"image_generation":{"model":"dall-e-3"},"system_message":{"supported":true},"web_search":{"toggleable":true},"tools":{"supported":true,"limit":128},"temperature":{"supported":false}},"model":"ray1","name":"Ray-1","suggestions":[],"speed":3,"provider_brand":"raycast","intelligence":4,"id":"raycast-ray1","provider":"raycast","description":"Raycast's Ray-1 model is based on GPT-4o and optimized for use with Raycast AI Extensions (beta).\n","context":127,"provider_name":"Raycast","availability":"public","features":["chat","quick_ai","commands"]},{"provider_name":"Raycast","context":127,"speed":2,"abilities":{"web_search":{"toggleable":true},"image_generation":{"model":"dall-e-3"},"tools":{"supported":true,"limit":128},"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"system_message":{"supported":true},"temperature":{"supported":false}},"intelligence":3,"description":"Raycast's Ray-1 mini model is based on GPT-4o mini and optimized for use with Raycast AI Extensions (beta).\n","availability":"public","provider_brand":"raycast","requires_better_ai":false,"provider":"raycast","name":"Ray-1 mini","suggestions":[],"features":["chat","quick_ai","commands"],"id":"raycast-ray1-mini","model":"ray1-mini"},{"availability":"public","model":"gpt-4.1","description":"GPT-4.1 is OpenAI's flagship model for complex tasks. It is well suited for problem solving across domains.\n","intelligence":4,"id":"openai-gpt-4.1","abilities":{"system_message":{"supported":true},"web_search":{"toggleable":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"image_generation":{"model":"dall-e-3"},"tools":{"supported":true},"temperature":{"supported":true}},"provider_brand":"openai","requires_better_ai":true,"name":"GPT-4.1","context":1000,"speed":2,"features":["chat","quick_ai","commands","api","emoji_search"],"provider":"openai","provider_name":"OpenAI","suggestions":["chat"]},{"context":1000,"model":"gpt-4.1-mini","abilities":{"web_search":{"toggleable":true},"system_message":{"supported":true},"tools":{"supported":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"temperature":{"supported":true},"image_generation":{"model":"dall-e-3"}},"provider":"openai","name":"GPT-4.1 mini","features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":["chat"],"description":"GPT-4.1 mini provides a balance between intelligence, speed, and cost that makes it an attractive model for many use cases.\n","id":"openai-gpt-4.1-mini","speed":3,"availability":"public","intelligence":4,"provider_brand":"openai","requires_better_ai":false,"provider_name":"OpenAI"},{"availability":"public","speed":4,"model":"gpt-4.1-nano","features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":["chat"],"context":1000,"intelligence":3,"provider":"openai","id":"openai-gpt-4.1-nano","name":"GPT-4.1 nano","provider_name":"OpenAI","provider_brand":"openai","requires_better_ai":false,"abilities":{"image_generation":{"model":"dall-e-3"},"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"tools":{"supported":true},"temperature":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":true}},"description":"GPT-4.1 nano is OpenAI's fastest, most cost-effective GPT-4.1 model.\n"},{"provider":"openai","availability":"public","description":"GPT-4 is the model with broad general knowledge, allowing it to follow complex instructions and solve difficult problems. This model is the previous generation, use GPT-4o for better results.\n","name":"GPT-4","suggestions":[],"requires_better_ai":true,"provider_brand":"openai","context":8,"features":["chat","quick_ai","commands","api","emoji_search"],"speed":1,"provider_name":"OpenAI","abilities":{"temperature":{"supported":true},"image_generation":{"model":"dall-e-3"},"web_search":{"toggleable":true},"system_message":{"supported":true}},"id":"openai-gpt-4","intelligence":1,"model":"gpt-4"},{"intelligence":1,"abilities":{"web_search":{"toggleable":true},"image_generation":{"model":"dall-e-3"},"temperature":{"supported":true},"system_message":{"supported":true}},"description":"GPT-4 Turbo is an evolution of the GPT-4 model with a larger context. This model is the previous generation, use GPT-4o for better results.\n","speed":1,"provider":"openai","model":"gpt-4-turbo","features":["chat","quick_ai","commands","api","emoji_search"],"availability":"public","name":"GPT-4 Turbo","provider_brand":"openai","suggestions":[],"id":"openai-gpt-4-turbo","context":127,"provider_name":"OpenAI","requires_better_ai":true},{"requires_better_ai":true,"context":127,"provider_name":"OpenAI","speed":3,"features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":["chat"],"provider_brand":"openai","abilities":{"temperature":{"supported":true},"image_generation":{"model":"dall-e-3"},"system_message":{"supported":true},"web_search":{"toggleable":true},"tools":{"supported":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]}},"name":"GPT-4o","id":"openai-gpt-4o","intelligence":3,"availability":"public","model":"gpt-4o","provider":"openai","description":"GPT-4o is the most advanced and fastest model from OpenAI, making it a great choice for complex everyday problems and deeper conversations.\n"},{"model":"gpt-4o-mini","provider_name":"OpenAI","description":"GPT-4o mini is a highly intelligent and fast model that is ideal for a variety of everyday tasks.\n","availability":"public","id":"openai-gpt-4o-mini","intelligence":3,"features":["chat","quick_ai","commands","api","emoji_search"],"provider":"openai","name":"GPT-4o mini","provider_brand":"openai","suggestions":["chat","quick_ai","commands"],"requires_better_ai":false,"speed":2,"context":127,"abilities":{"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"temperature":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":true},"image_generation":{"model":"dall-e-3"},"tools":{"supported":true}}},{"context":200,"provider":"openai_o1","features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":[],"availability":"public","intelligence":4,"speed":2,"id":"openai_o1-o3","provider_name":"OpenAI","name":"o3","abilities":{"temperature":{"supported":false},"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"web_search":{"toggleable":true},"reasoning_effort":{"supported":true},"tools":{"supported":true},"system_message":{"supported":true}},"provider_brand":"openai","description":"OpenAI o3 is a well-rounded and powerful model across domains. It sets a new standard for math, science, coding, and visual reasoning tasks.\n","requires_better_ai":true,"model":"o3"},{"provider":"openai_o1","availability":"public","id":"openai_o1-o4-mini","provider_brand":"openai","model":"o4-mini","description":"o4-mini is OpenAI's latest small o-series model. It's optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks.\n","abilities":{"reasoning_effort":{"supported":true},"tools":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"temperature":{"supported":false}},"features":["chat","quick_ai","commands","api","emoji_search"],"provider_name":"OpenAI","context":200,"intelligence":4,"name":"o4-mini","suggestions":[],"speed":3,"requires_better_ai":false},{"abilities":{"system_message":{"supported":false},"temperature":{"supported":false}},"provider_brand":"openai","provider":"openai_o1","description":"OpenAI o1-preview is an advanced reasoning model designed to tackle complex problems in science, coding, mathematics, and similar fields.\n","speed":3,"suggestions":[],"requires_better_ai":true,"availability":"public","provider_name":"OpenAI","name":"o1-preview","model":"o1-preview","id":"openai_o1-o1-preview","intelligence":3,"features":["chat","quick_ai","commands","api","emoji_search"],"context":128},{"context":128,"abilities":{"system_message":{"supported":false},"temperature":{"supported":false}},"provider_name":"OpenAI","availability":"public","id":"openai_o1-o1-mini","name":"o1-mini","description":"OpenAI o1-mini is a faster, more cost-effective reasoning model particularly effective at coding tasks.\n","provider":"openai_o1","intelligence":4,"model":"o1-mini","features":["chat","quick_ai","commands","api","emoji_search"],"requires_better_ai":true,"speed":3,"suggestions":[],"provider_brand":"openai"},{"name":"o1","id":"openai_o1-o1","suggestions":[],"model":"o1-2024-12-17","requires_better_ai":true,"provider":"openai_o1","provider_name":"OpenAI","availability":"public","provider_brand":"openai","abilities":{"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"temperature":{"supported":false},"reasoning_effort":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":true}},"speed":2,"context":200,"intelligence":4,"features":["chat","quick_ai","commands","api","emoji_search"],"description":"OpenAI o1 is an advanced reasoning model designed to tackle complex problems in science, coding, mathematics, and similar fields.\n"},{"speed":3,"context":200,"provider":"openai_o1","provider_brand":"openai","features":["chat","quick_ai","commands","api","emoji_search"],"availability":"public","model":"o3-mini","requires_better_ai":false,"abilities":{"reasoning_effort":{"supported":true},"temperature":{"supported":false},"tools":{"supported":true},"web_search":{"toggleable":true},"system_message":{"supported":true}},"description":"OpenAI o3-mini is a fast and powerful reasoning model optimized for STEM tasks like science, math, and coding. It offers advanced features like web search making it ideal for complex problem-solving with reduced latency.\n","name":"o3-mini","intelligence":4,"suggestions":[],"provider_name":"OpenAI","id":"openai_o1-o3-mini"},{"availability":"public","suggestions":["quick_ai"],"features":["chat","quick_ai","commands","api"],"model":"claude-3-5-haiku-latest","context":200,"requires_better_ai":false,"provider_brand":"anthropic","intelligence":3,"name":"Claude 3.5 Haiku","provider_name":"Anthropic","id":"anthropic-claude-haiku","description":"Claude 3.5 Haiku is Anthropic's fastest model, with a large context window that makes it ideal for analyzing code, documents, or large amounts of text.\n","provider":"anthropic","abilities":{"tools":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":true},"temperature":{"supported":true}},"speed":1},{"description":"Claude 3.5 Sonnet from Anthropic has enhanced intelligence with increased speed. It excels at complex tasks like visual reasoning or workflow orchestrations. Currently points to claude-3-5-sonnet-20241022.\n","provider":"anthropic","model":"claude-3-5-sonnet-latest","requires_better_ai":true,"provider_name":"Anthropic","abilities":{"temperature":{"supported":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"web_search":{"toggleable":true},"tools":{"supported":true},"system_message":{"supported":true}},"intelligence":3,"features":["chat","quick_ai","commands","api"],"context":200,"id":"anthropic-claude-sonnet","provider_brand":"anthropic","suggestions":["commands","chat"],"name":"Claude 3.5 Sonnet","speed":2,"availability":"public"},{"intelligence":3,"description":"Claude 3.7 Sonnet is Anthropic's most intelligent model\n","name":"Claude 3.7 Sonnet","provider_name":"Anthropic","speed":2,"context":200,"model":"claude-3-7-sonnet-latest","requires_better_ai":true,"suggestions":["commands","chat"],"id":"anthropic-claude-3-7-sonnet-latest","abilities":{"temperature":{"supported":true},"tools":{"supported":true},"web_search":{"toggleable":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"system_message":{"supported":true}},"features":["chat","quick_ai","commands","api"],"availability":"public","provider_brand":"anthropic","provider":"anthropic"},{"availability":"public","provider_brand":"anthropic","description":"Claude 3.7 Sonnet (Reasoning) is Anthropic's most intelligent model with reasoning support.\n","context":200,"id":"anthropic-claude-3-7-sonnet-latest-reasoning","name":"Claude 3.7 Sonnet (Reasoning)","requires_better_ai":true,"intelligence":4,"abilities":{"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"web_search":{"toggleable":true},"reasoning_effort":{"supported":true},"system_message":{"supported":true},"temperature":{"supported":false}},"features":["chat","quick_ai","commands","api"],"speed":2,"provider_name":"Anthropic","suggestions":["commands","chat"],"provider":"anthropic","model":"claude-3-7-sonnet-latest-reasoning"},{"provider_name":"Anthropic","intelligence":3,"context":200,"features":["chat","quick_ai","commands","api"],"suggestions":[],"availability":"public","description":"Claude 3 Opus is Anthropic's intelligent model designed to solve highly complex tasks. It stands out for its remarkable fluency.\n","provider_brand":"anthropic","requires_better_ai":true,"name":"Claude 3 Opus","model":"claude-3-opus-20240229","id":"anthropic-claude-opus","abilities":{"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"web_search":{"toggleable":true},"system_message":{"supported":true},"temperature":{"supported":true}},"provider":"anthropic","speed":1},{"abilities":{"temperature":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":false}},"intelligence":3,"model":"sonar","features":["chat","quick_ai","commands","api","emoji_search"],"description":"Lightweight Perplexity model with search grounding, quicker than Sonar Pro\n","provider_name":"Perplexity","speed":2,"suggestions":["quick_ai"],"context":127,"availability":"public","provider":"perplexity","provider_brand":"perplexity","name":"Sonar","id":"perplexity-sonar","requires_better_ai":false},{"speed":2,"availability":"public","description":"Premier Perplexity model with search grounding, supporting advanced queries and follow-ups\n","model":"sonar-pro","id":"perplexity-sonar-pro","provider_brand":"perplexity","features":["chat","quick_ai","commands","api","emoji_search"],"requires_better_ai":true,"intelligence":3,"provider":"perplexity","provider_name":"Perplexity","name":"Sonar Pro","abilities":{"system_message":{"supported":true},"web_search":{"toggleable":false},"temperature":{"supported":true}},"suggestions":["quick_ai"],"context":200},{"provider_name":"Perplexity","context":127,"model":"sonar-reasoning","requires_better_ai":false,"suggestions":["quick_ai"],"speed":2,"name":"Sonar Reasoning","provider_brand":"perplexity","intelligence":3,"id":"perplexity-sonar-reasoning","features":["chat","quick_ai","commands","api","emoji_search"],"provider":"perplexity","description":"Lightweight reasoning offering powered by reasoning models trained with DeepSeek R1.\n","availability":"public","abilities":{"system_message":{"supported":true},"web_search":{"toggleable":false},"temperature":{"supported":true}}},{"speed":1,"requires_better_ai":false,"suggestions":["quick_ai"],"availability":"public","provider":"perplexity","provider_brand":"perplexity","abilities":{"web_search":{"toggleable":false},"temperature":{"supported":true},"system_message":{"supported":true}},"intelligence":3,"features":["chat","quick_ai","commands","api","emoji_search"],"name":"Sonar Reasoning Pro","context":127,"model":"sonar-reasoning-pro","description":"Premier reasoning offering powered by DeepSeek R1.\n","provider_name":"Perplexity","id":"perplexity-sonar-reasoning-pro"},{"availability":"public","suggestions":[],"provider":"groq","model":"meta-llama\/llama-4-scout-17b-16e-instruct","description":"Llama 4 Scout is a cutting-edge multimodal model with 17 billion active parameters and 16 experts, designed for state-of-the-art performance in its class.\n","abilities":{"web_search":{"toggleable":true},"tools":{"supported":true},"system_message":{"supported":true},"temperature":{"supported":true}},"requires_better_ai":false,"id":"groq-meta-llama\/llama-4-scout-17b-16e-instruct","speed":4,"features":["chat","quick_ai","commands","api","emoji_search"],"intelligence":3,"context":131,"provider_brand":"meta","provider_name":"Groq","name":"Llama 4 Scout"},{"model":"llama-3.3-70b-versatile","provider_name":"Groq","provider":"groq","description":"Llama 3.3 70B is an open-source model from Meta, state-of-the-art in areas like reasoning, math, and general knowledge.\n","suggestions":[],"intelligence":3,"provider_brand":"meta","id":"groq-llama-3.3-70b-versatile","abilities":{"temperature":{"supported":true},"system_message":{"supported":true},"tools":{"supported":true},"web_search":{"toggleable":true}},"speed":4,"context":128,"availability":"public","requires_better_ai":false,"features":["chat","quick_ai","commands","api","emoji_search"],"name":"Llama 3.3 70B"},{"name":"Llama 3.1 8B","provider":"groq","speed":5,"requires_better_ai":false,"availability":"public","suggestions":[],"provider_name":"Groq","id":"groq-llama-3.1-8b-instant","intelligence":2,"context":128,"abilities":{"system_message":{"supported":true},"web_search":{"toggleable":true},"temperature":{"supported":true}},"model":"llama-3.1-8b-instant","features":["chat","quick_ai","commands","api","emoji_search"],"provider_brand":"meta","description":"Llama 3.1 8B is an open-source model from Meta, optimized for instruction following and high-speed performance.\n"},{"abilities":{"system_message":{"supported":true},"web_search":{"toggleable":true},"temperature":{"supported":true}},"provider":"groq","name":"Llama 3 70B","model":"llama3-70b-8192","suggestions":["commands"],"features":["chat","quick_ai","commands","api","emoji_search"],"speed":4,"provider_brand":"meta","id":"groq-llama3-70b-8192","intelligence":2,"description":"Llama 3 70B from Meta is a highly capable open-source LLM that can serve as a tool for various text-related tasks.\n","context":8,"requires_better_ai":false,"availability":"public","provider_name":"Groq"},{"name":"Llama 3.1 405B","description":"Llama 3.1 405B is Meta's flagship open-source model, offering unparalleled capabilities in general knowledge, steerability, math, tool use, and multilingual translation.\n","abilities":{"temperature":{"supported":true},"system_message":{"supported":true}},"context":8,"suggestions":[],"provider_brand":"meta","availability":"public","speed":1,"provider":"together","model":"meta-llama\/Meta-Llama-3.1-405B-Instruct-Turbo","id":"together-meta-llama\/Meta-Llama-3.1-405B-Instruct-Turbo","requires_better_ai":true,"provider_name":"Together AI","features":["chat","quick_ai","commands","api","emoji_search"],"intelligence":3},{"name":"Mistral Nemo","intelligence":2,"availability":"public","speed":3,"suggestions":[],"requires_better_ai":false,"model":"open-mistral-nemo","context":128,"provider":"mistral","features":["chat","quick_ai","commands","api","emoji_search"],"provider_brand":"mistral","abilities":{"system_message":{"supported":true},"web_search":{"toggleable":true},"temperature":{"supported":true}},"description":"Mistral Nemo is a small model built in collaboration with NVIDIA, and released under the Apache 2.0 license.\n","id":"mistral-open-mistral-nemo","provider_name":"Mistral"},{"intelligence":3,"features":["chat","quick_ai","commands","api","emoji_search"],"abilities":{"temperature":{"supported":true},"tools":{"supported":true},"web_search":{"toggleable":true},"system_message":{"supported":true}},"context":128,"model":"mistral-large-latest","suggestions":[],"availability":"public","provider":"mistral","provider_brand":"mistral","provider_name":"Mistral","requires_better_ai":true,"name":"Mistral Large","id":"mistral-mistral-large-latest","description":"Mistral Large is Mistral's top-tier reasoning model for high-complexity tasks with stronger multilingual support. Currently points to mistral-large-2411\n","speed":1},{"requires_better_ai":false,"speed":2,"description":"Mistral Small is Mistral's latest enterprise-grade small model that delivers significant improvements in human alignment, reasoning capabilities, and code. Currently points to mistral-small-2503\n","availability":"public","model":"mistral-small-latest","name":"Mistral Small 3","provider_name":"Mistral","abilities":{"temperature":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":true},"tools":{"supported":true}},"intelligence":3,"suggestions":[],"features":["chat","quick_ai","commands","api","emoji_search"],"provider":"mistral","id":"mistral-mistral-small-latest","context":32,"provider_brand":"mistral"},{"name":"Codestral","provider_name":"Mistral","description":"Codestral is Mistral's cutting-edge language model that specializes in low-latency, high-frequency tasks such as fill-in-the-middle (FIM), code correction and test generation. Currently points to codestral-2501\n","context":256,"id":"mistral-codestral-latest","provider":"mistral","intelligence":2,"suggestions":[],"provider_brand":"mistral","requires_better_ai":false,"abilities":{"web_search":{"toggleable":true},"temperature":{"supported":true},"system_message":{"supported":true}},"features":["chat","quick_ai","commands","api","emoji_search"],"model":"codestral-latest","availability":"public","speed":3},{"abilities":{"temperature":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":true}},"model":"deepseek-r1-distill-llama-70b","context":128,"provider_brand":"deepseek","description":"DeepSeek R1 Distill Llama 3.3 70B is a fine-tuned version of Llama 3.3 70B, leveraging DeepSeek-R1's advanced capabilities for enhanced reasoning and precision.\n","speed":3,"provider_name":"Groq","name":"DeepSeek R1 Distill Llama 3.3 70B","features":["chat","quick_ai","commands","api","emoji_search"],"availability":"public","intelligence":3,"requires_better_ai":false,"id":"groq-deepseek-r1-distill-llama-70b","provider":"groq","suggestions":[]},{"suggestions":[],"provider_brand":"alibaba","intelligence":3,"name":"Qwen-2.5-32B","features":["chat","quick_ai","commands","api","emoji_search"],"provider":"groq","id":"groq-qwen-2.5-32b","description":"Qwen-2.5-32B is Alibaba's flagship model, delivering near-instant responses with GPT-4 level capabilities across a wide range of tasks.\n","abilities":{"temperature":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":true}},"provider_name":"Groq","speed":3,"availability":"deprecated","requires_better_ai":false,"context":128,"model":"qwen-2.5-32b"},{"availability":"public","provider":"google","requires_better_ai":true,"model":"gemini-2.5-pro-preview-03-25","description":"Gemini 2.5 is a thinking model, designed to tackle increasingly complex problems.\n","context":1000,"provider_brand":"google","abilities":{"temperature":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":true},"tools":{"supported":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp"]}},"id":"google-gemini-2.5-pro","provider_name":"Google","speed":3,"name":"Gemini 2.5 Pro","intelligence":5,"features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":[]},{"speed":3,"availability":"deprecated","name":"Gemini 1.5 Flash","requires_better_ai":false,"model":"gemini-1.5-flash","intelligence":3,"description":"Google's fastest multimodal model with exceptional speed and efficiency for quick, high-frequency tasks\n","id":"google-gemini-1.5-flash","suggestions":[],"context":1000,"features":["chat","quick_ai","commands","api","emoji_search"],"provider":"google","provider_name":"Google","provider_brand":"google","abilities":{"vision":{"formats":["image\/png","image\/jpeg","image\/webp"]},"web_search":{"toggleable":true},"temperature":{"supported":true},"system_message":{"supported":true}}},{"description":"Google's high-performing multimodal model for complex tasks requiring deep reasoning and nuanced understanding\n","provider":"google","abilities":{"web_search":{"toggleable":true},"temperature":{"supported":true},"system_message":{"supported":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp"]}},"requires_better_ai":true,"suggestions":[],"intelligence":3,"speed":2,"context":2097,"provider_name":"Google","provider_brand":"google","model":"gemini-1.5-pro","name":"Gemini 1.5 Pro","features":["chat","quick_ai","commands","api","emoji_search"],"availability":"deprecated","id":"google-gemini-1.5-pro"},{"requires_better_ai":false,"intelligence":3,"model":"gemini-2.5-flash-preview-04-17","suggestions":[],"speed":3,"description":"Google's Gemini 2.5 Flash is a thinking model that offers great, well-rounded capabilities\n","availability":"public","id":"google-gemini-2.5-flash","context":1000,"features":["chat","quick_ai","commands","api","emoji_search","summary"],"provider_name":"Google","provider":"google","provider_brand":"google","name":"Gemini 2.5 Flash","abilities":{"system_message":{"supported":true},"tools":{"supported":true},"temperature":{"supported":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp"]},"reasoning_effort":{"supported":true},"web_search":{"toggleable":true}}},{"speed":3,"description":"Google's powerful workhorse model with low latency and enhanced performance, built to power agentic experiences\n","id":"google-gemini-2.0-flash","provider_brand":"google","abilities":{"temperature":{"supported":true},"tools":{"supported":true},"system_message":{"supported":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp"]},"web_search":{"toggleable":true}},"provider_name":"Google","suggestions":[],"context":1000,"provider":"google","name":"Gemini 2.0 Flash","model":"gemini-2.0-flash","requires_better_ai":false,"availability":"public","intelligence":3,"features":["chat","quick_ai","commands","api","emoji_search","summary"]},{"context":1000,"description":"Gemini 2.0 Flash Thinking is an experimental model that generates its internal reasoning process, enabling stronger analytical capabilities\n","requires_better_ai":false,"provider":"google","suggestions":[],"features":["chat","quick_ai","commands","api","emoji_search"],"availability":"public","name":"Gemini 2.0 Flash Thinking","provider_name":"Google","abilities":{"temperature":{"supported":true},"system_message":{"supported":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp"]}},"id":"google-gemini-2.0-flash-thinking","speed":3,"provider_brand":"google","intelligence":4,"model":"gemini-2.0-flash-thinking-exp-01-21"},{"availability":"public","speed":1,"suggestions":[],"model":"deepseek-ai\/DeepSeek-R1","context":64,"provider_brand":"deepseek","abilities":{"system_message":{"supported":true},"temperature":{"supported":true}},"provider_name":"Together AI","id":"together-deepseek-ai\/DeepSeek-R1","intelligence":4,"provider":"together","features":["chat","quick_ai","commands","api","emoji_search"],"name":"DeepSeek-R1","requires_better_ai":true,"description":"Fully open-source model with performance on par with OpenAI-o1\n"},{"suggestions":[],"id":"together-deepseek-ai\/DeepSeek-V3","provider":"together","features":["chat","quick_ai","commands","api","emoji_search"],"context":128,"requires_better_ai":false,"availability":"public","model":"deepseek-ai\/DeepSeek-V3","speed":1,"provider_brand":"deepseek","abilities":{"temperature":{"supported":true},"system_message":{"supported":true}},"intelligence":4,"description":"Mixture-of-Experts model challenging top AI models\n","provider_name":"Together AI","name":"DeepSeek-V3"},{"availability":"public","provider_name":"xAI","requires_better_ai":true,"name":"Grok-3 Beta","context":127,"features":["chat","quick_ai","commands","api","emoji_search"],"provider_brand":"xai","description":"Grok-3 is xAI's flagship model that excels at enterprise use cases like data extraction, coding, and text summarization. Always uses fast-mode","abilities":{"temperature":{"supported":true},"tools":{"supported":true},"system_message":{"supported":true},"web_search":{"toggleable":true}},"provider":"xai","id":"xai-grok-3","model":"grok-3-fast-beta","intelligence":3,"speed":1,"suggestions":[]},{"model":"grok-3-mini-fast-beta","context":127,"abilities":{"web_search":{"toggleable":true},"reasoning_effort":{"supported":true},"temperature":{"supported":true},"tools":{"supported":true},"system_message":{"supported":true}},"provider_name":"xAI","features":["chat","quick_ai","commands","api","emoji_search"],"provider_brand":"xai","speed":1,"provider":"xai","requires_better_ai":false,"availability":"public","description":"Grok-3 Mini is xAI's lightweight model that thinks before responding. Fast, smart, and great for logic-based tasks that do not require deep domain knowledge. Always uses fast-mode","name":"Grok-3 Mini Beta","id":"xai-grok-3-mini","suggestions":[],"intelligence":3},{"features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":[],"provider_brand":"xai","availability":"public","abilities":{"tools":{"supported":true},"web_search":{"toggleable":true},"vision":{"formats":["image\/png","image\/jpeg","image\/webp","image\/gif"]},"system_message":{"supported":true},"temperature":{"supported":true}},"context":127,"id":"xai-grok-2-latest","description":"Grok-2 is xAI's frontier language model with state-of-the-art reasoning capabilities","name":"Grok-2","speed":1,"model":"grok-2-latest","provider_name":"xAI","requires_better_ai":true,"intelligence":3,"provider":"xai"}],"default_models":{"commands":"openai-gpt-4o-mini","chat":"openai-gpt-4o-mini","summary":"google-gemini-2.0-flash","tools":"raycast-ray1","emoji_search":"openai-gpt-4o-mini","api":"openai-gpt-4o-mini","quick_ai":"openai-gpt-4o-mini"}}		¯†‡ˆ‰Š‹Œ‘’“”•–—˜™š›œ_$30f5a222-3c9a-4edd-834d-649943634272_$5f2e08d5-fdf1-4171-b252-aa53065621b4_$40ebc708-964f-473b-8d19-d4e9cbd27ae9_$5fdb86d3-dfcc-45a7-8969-8113b51434ab_$b5526a94-aa8f-4e54-958c-97080312a465_$6d35b3a5-ae12-48b1-b5de-616a22387eae_$319782b6-6050-4568-89b5-194c84709f83_$31c4aebe-5f43-4487-9d97-b6e92754eba8_$8fb73ce6-b87b-4088-a9af-71e5b44e36c2_$cc4b2f8f-6017-4327-9563-d2677ee9b576_$d1069f4b-896d-440f-a8c6-0468f61a9d5b_$bd66a1ad-75d7-4b26-8ea7-92fcc9adf473_$e78de50b-216a-47aa-a5d9-f517f6aec4fa_$ce226a1f-7f1c-4680-8735-aa462793bca5_$36bf10e7-082e-465c-9983-2708e46f3b09_$0a3cf1ce-7de6-415c-9e37-91a892d1747e_$6d6a05b4-6003-4d28-afae-a9b721d11594_$951560e5-15cb-4c8d-9bfd-8c8d4008c461_$d3e7311b-4072-498b-aeb6-4da257176d80_$320f40ef-a633-415a-ab0e-1e99515478f7_$6090553e-ee96-4c89-af5c-e6c60fa551ba_$a27daf43-1a9d-4720-9a21-f2d47bc399c4_$4d342edf-4371-498e-8ead-a424d65f933f	_$95A838B9-0875-42C4-B2BC-82CFDF883CB5ZCommand-49	"F2 "F* 	_572 543 800 448 0 0 1920 1175 «§¨©ª«¬­®¯°±_raycastShortcuts_installFirstExtensionXsnippets_startWalkthrough_windowManagement_setHotkeyAndAlias_openActionPanelZquicklinks]floatingNotesZcalculatorXcalendar£³´µ_builtin_package_snippets_ builtin_package_clipboardHistory_6extension_raynab__319782b6-6050-4568-89b5-194c84709f83#AÚ*º¡é	 	Wdefault	Ğ_(2fb56791dd99e089ebdb97d2e450ce434cd03e25	O%{"succeeded":{"_0":767612225.356852}}		 ¢ÆÇ_30.000000, 0.000000, 256.000000, 1000.000000, NO, NO_5257.000000, 0.000000, 390.000000, 1000.000000, NO, NO\bundled-noon	SallV1.96.3	#AÚ+¬[=.3AÆÄÇxGñH"1.91.1"3AÆ¬ÕÂ^bundled-sunset	Ushort		Ularge	3AÆ¬âØË	3AÆàÈ¸   P			¤âãäåSEscb# ,b# Wd# E s cVlegacyOèbookè    0                                   À               Users        flo 	     Documents               ,        –O           õz           îD          T   d   t         AÃ¥à%€                                                 õ     	  file:///     Macintosh HD      ‚–ç         AÆ©?G€  $     5224EA2D-1778-47B5-96BA-E37A9E28605A           ï     ï          /   0     dnib                               scod       ğ   şÿÿÿ            @         „         ¨       @  ˜          |         ì          ü          0                             \      0   È       À  Ğ       À          À  à       Ğ  È       Ğ         ğ  ,       "ğ  ˆ      "F0ô 	V15.3.1Oü[{"displayName":"DALLÂ·E 3","description":"Generate an image using DALLÂ·E 3","icon":"image","mentionName":"dalle","tools":[{"displayName":"DALLÂ·E 3","displayDescription":"Generate image using DALLÂ·E 3","mentionName":"dalle","name":"dalle"}],"exampleSuggestions":["A vintage mac computer from the 90s in the style of a pencil sketch","A software engineer working with many displays, lots of neon, and flying cars outside","Technical illustration of a mobile phone with a folding touchscreen"]},{"exampleSuggestions":["A vintage mac computer from the 90s in the style of a pencil sketch","A software engineer working with many displays, lots of neon, and flying cars outside","Technical illustration of a mobile phone with a folding touchscreen"],"description":"Generate an image using GPT Image 1","icon":"image","displayName":"GPT Image 1","tools":[{"name":"gpt_image","displayName":"Gpt Image","displayDescription":"Generate image using Gpt Image","mentionName":"gpt_image"}],"mentionName":"gpt_image"},{"exampleSuggestions":["What's the latest news in AI","Who are the founders of Raycast","When is the next local holiday","What do the Raycast founders look like","Get the Raycast logo"],"icon":"globe01","description":"Allows AI to do a simple web search. When enabled, AI will choose when to search the web or not.","mentionName":"web","displayName":"Web","tools":[{"displayName":"Web Search","displayDescription":"Search web for information","name":"web_search","mentionName":"web"},{"displayDescription":"Search images related to the user input","name":"search_images","displayName":"Search Images","mentionName":"web"}]},{"mentionName":"chart","tools":[{"displayDescription":"Draw a chart","mentionName":"chart","name":"chart","displayName":"Chart"}],"displayName":"Chart","description":"Draw a simple chart to view data more clearly","icon":"barChart","exampleSuggestions":["Create a chart with the data from this attachment","Help me visualise this [clipboard history] information"]},{"tools":[{"name":"flux","displayDescription":"Generate image using Flux 1.1 Pro","displayName":"Flux 1.1 Pro","mentionName":"flux"}],"mentionName":"flux","description":"Generate an image using Flux 1.1 Pro","exampleSuggestions":["A vintage mac computer from the 90s in the style of a pencil sketch","A minimalistic mockup of an iPad with a blank screen facing the viewer","A brick wall in Shoreditch London, with spray painted text in red saying: Raycast"],"displayName":"Flux 1.1 Pro","icon":"image"},{"displayName":"Stable Diffusion 3.5 Medium","mentionName":"stable_diffusion","icon":"image","description":"Generate an image using Stable Diffusion 3.5 Medium","exampleSuggestions":["A vintage mac computer from the 90s in the style of a pencil sketch","Simplistic Nordic style interior of a small home office with a standing desk, lots of oak wood, natural light, large plants."],"tools":[{"displayName":"Stable Diffusion 3.5 Medium","displayDescription":"Generate image using Stable Diffusion 3.5 Medium","name":"stable_diffusion","mentionName":"stable_diffusion"}]}]	_1302 81 498 800 0 0 1800 1125   ± Ë à8ºŞ÷:_‰©Èâø(T·Íç$S¹ç >d‰³Êø-Ut£âFa’¿ë9dƒ¼å	
	(	B	h	À	ï


7
U
ƒ
£
ş1ŸÑèh†˜±9Wi†¥Ãéê )*-|}ŸÆç+MkŠ§Æä%Gd…£ÄÑŞëö"/;HS`kx†X†Y†Z†\†v††Ä†ë‡‡9‡`‡‡‡®‡Õ‡üˆ#ˆJˆqˆ˜ˆ¿ˆæ‰‰4‰[‰‚‰©‰Ğ‰÷‰øŠŠ*Š+Š0Š5Š6Š7ŠXŠdŠwŠŠ˜Š«Š¾ŠÒŠäŠïŠı‹‹‹‹0‹S‹Œ‹•‹–‹—‹˜‹ ‹¡‹¢‹Í‹Î‹ö‹÷‹ø‹ù‹ú‹û‹şŒ4ŒlŒyŒzŒ~Œ…Œ†ŒŒ˜Œ¡ŒªŒ¹ŒºŒÀŒÁŒÂŒÃŒÉŒÊŒÓŒÔŒİŒŞŒßŒàŒáŒâŒçŒëŒğŒõŒşñö÷şÿ›ÿœ œ             ğ              œ"